{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"0\"></a>\n",
    "# [Tweet Sentiment Extraction](https://www.kaggle.com/c/tweet-sentiment-extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## 1. Import libraries <a class=\"anchor\" id=\"1\"></a>\n",
    "\n",
    "[Back to Table of Contents](#0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "import seaborn as sns; sns.set(style='white')\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "from scipy.cluster import hierarchy\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from transformers import *\n",
    "import tokenizers\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "from tensorflow.keras.layers import Bidirectional, GlobalMaxPool1D,Bidirectional\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "#from tensorflow.keras.models import Model\n",
    "#from tensorflow.keras.layers import TimeDistributed\n",
    "#from tensorflow.keras.layers import concatenate\n",
    "\n",
    "import gc\n",
    "\n",
    "pd.set_option('max_colwidth', 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## 2. Download data & FE <a class=\"anchor\" id=\"2\"></a>\n",
    "\n",
    "[Back to Table of Contents](#0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Code from notebook https://www.kaggle.com/khoongweihao/tse2020-roberta-cnn-random-seed-distribution?scriptVersionId=34448972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in Sa...</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                     text  \\\n",
       "0  cb774db0d1      I`d have responded, if I were going   \n",
       "1  549e992a42   Sooo SAD I will miss you here in Sa...   \n",
       "2  088c60f138                my boss is bullying me...   \n",
       "3  9642c003ef           what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = 96\n",
    "PATH = '../input/tf-roberta/'\n",
    "tokenizer = tokenizers.ByteLevelBPETokenizer(\n",
    "    vocab_file=PATH+'vocab-roberta-base.json', \n",
    "    merges_file=PATH+'merges-roberta-base.txt', \n",
    "    lowercase=True,\n",
    "    add_prefix_space=True\n",
    ")\n",
    "EPOCHS = 3 # originally 3\n",
    "BATCH_SIZE = 32 # originally 32\n",
    "PAD_ID = 1\n",
    "SEED = 88888\n",
    "LABEL_SMOOTHING = 0.1\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "sentiment_id = {'positive': 1313, 'negative': 2430, 'neutral': 7974}\n",
    "train = pd.read_csv('../input/tweet-sentiment-extraction/train.csv').fillna('')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('../input/tweet-sentiment-extraction/test.csv').fillna('')\n",
    "\n",
    "ct = test.shape[0]\n",
    "input_ids_t = np.ones((ct,MAX_LEN),dtype='int32')\n",
    "attention_mask_t = np.zeros((ct,MAX_LEN),dtype='int32')\n",
    "token_type_ids_t = np.zeros((ct,MAX_LEN),dtype='int32')\n",
    "\n",
    "for k in range(test.shape[0]):\n",
    "        \n",
    "    # INPUT_IDS\n",
    "    text1 = \" \"+\" \".join(test.loc[k,'text'].split())\n",
    "    enc = tokenizer.encode(text1)                \n",
    "    s_tok = sentiment_id[test.loc[k,'sentiment']]\n",
    "    input_ids_t[k,:len(enc.ids)+3] = [0, s_tok] + enc.ids + [2]\n",
    "    attention_mask_t[k,:len(enc.ids)+3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dropout_new = 0.15     # originally 0.1\n",
    "n_split = 5            # originally 5\n",
    "lr = 3e-5              # originally 3e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## 3.2. Model training <a class=\"anchor\" id=\"3.2\"></a>\n",
    "\n",
    "[Back to Table of Contents](#0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_weights(model, dst_fn):\n",
    "    weights = model.get_weights()\n",
    "    with open(dst_fn, 'wb') as f:\n",
    "        pickle.dump(weights, f)\n",
    "\n",
    "\n",
    "def load_weights(model, weight_fn):\n",
    "    with open(weight_fn, 'rb') as f:\n",
    "        weights = pickle.load(f)\n",
    "    model.set_weights(weights)\n",
    "    return model\n",
    "\n",
    "def loss_fn(y_true, y_pred):\n",
    "    # adjust the targets for sequence bucketing\n",
    "    ll = tf.shape(y_pred)[1]\n",
    "    y_true = y_true[:, :ll]\n",
    "    loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred,\n",
    "        from_logits=False, label_smoothing=LABEL_SMOOTHING)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss\n",
    "\n",
    "\n",
    "def build_model_base():\n",
    "    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    tok = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    padding = tf.cast(tf.equal(ids, PAD_ID), tf.int32)\n",
    "\n",
    "    lens = MAX_LEN - tf.reduce_sum(padding, -1)\n",
    "    max_len = tf.reduce_max(lens)\n",
    "    ids_ = ids[:, :max_len]\n",
    "    att_ = att[:, :max_len]\n",
    "    tok_ = tok[:, :max_len]\n",
    "\n",
    "    config = RobertaConfig.from_pretrained(PATH+'config-roberta-base.json')\n",
    "    bert_model = TFRobertaModel.from_pretrained(PATH+'pretrained-roberta-base.h5',config=config)\n",
    "    x = bert_model(ids_,attention_mask=att_,token_type_ids=tok_)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dropout(Dropout_new)(x[0])\n",
    "    x1 = tf.keras.layers.Conv1D(768, 2,padding='same')(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    #shapeミスった。\n",
    "    x1 = tf.keras.layers.Conv1D(64, 2,padding='same')(x1)\n",
    "    x1 = tf.keras.layers.Dense(1)(x1)\n",
    "    x1 = tf.keras.layers.Flatten()(x1)\n",
    "    x1 = tf.keras.layers.Activation('softmax')(x1)\n",
    "    \n",
    "    x2 = tf.keras.layers.Dropout(Dropout_new)(x[0]) \n",
    "    x2 = tf.keras.layers.Conv1D(768, 2,padding='same')(x2)\n",
    "    x2 = tf.keras.layers.LeakyReLU()(x2)\n",
    "    x2 = tf.keras.layers.Conv1D(64, 2, padding='same')(x2)\n",
    "    x2 = tf.keras.layers.Dense(1)(x2)\n",
    "    x2 = tf.keras.layers.Flatten()(x2)\n",
    "    x2 = tf.keras.layers.Activation('softmax')(x2)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1,x2])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr) \n",
    "    model.compile(loss=loss_fn, optimizer=optimizer)\n",
    "    \n",
    "    # this is required as `model.predict` needs a fixed size!\n",
    "    x1_padded = tf.pad(x1, [[0, 0], [0, MAX_LEN - max_len]], constant_values=0.)\n",
    "    x2_padded = tf.pad(x2, [[0, 0], [0, MAX_LEN - max_len]], constant_values=0.)\n",
    "    \n",
    "    padded_model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1_padded,x2_padded])\n",
    "    return model, padded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_drop_bef64():\n",
    "    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    tok = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    padding = tf.cast(tf.equal(ids, PAD_ID), tf.int32)\n",
    "\n",
    "    lens = MAX_LEN - tf.reduce_sum(padding, -1)\n",
    "    max_len = tf.reduce_max(lens)\n",
    "    ids_ = ids[:, :max_len]\n",
    "    att_ = att[:, :max_len]\n",
    "    tok_ = tok[:, :max_len]\n",
    "\n",
    "    config = RobertaConfig.from_pretrained(PATH+'config-roberta-base.json')\n",
    "    bert_model = TFRobertaModel.from_pretrained(PATH+'pretrained-roberta-base.h5',config=config)\n",
    "    x = bert_model(ids_,attention_mask=att_,token_type_ids=tok_)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dropout(Dropout_new)(x[0])\n",
    "    x1 = tf.keras.layers.Conv1D(768, 2,padding='same')(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dropout(Dropout_new)(x1)\n",
    "    x1 = tf.keras.layers.Conv1D(64, 2,padding='same')(x1)\n",
    "    x1 = tf.keras.layers.Dense(1)(x1)\n",
    "    x1 = tf.keras.layers.Flatten()(x1)\n",
    "    x1 = tf.keras.layers.Activation('softmax')(x1)\n",
    "    \n",
    "    x2 = tf.keras.layers.Dropout(Dropout_new)(x[0]) \n",
    "    x2 = tf.keras.layers.Conv1D(768, 2,padding='same')(x2)\n",
    "    x2 = tf.keras.layers.LeakyReLU()(x2)\n",
    "    x2 = tf.keras.layers.Dropout(Dropout_new)(x2) \n",
    "    x2 = tf.keras.layers.Conv1D(64, 2, padding='same')(x2)\n",
    "    x2 = tf.keras.layers.Dense(1)(x2)\n",
    "    x2 = tf.keras.layers.Flatten()(x2)\n",
    "    x2 = tf.keras.layers.Activation('softmax')(x2)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1,x2])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr) \n",
    "    model.compile(loss=loss_fn, optimizer=optimizer)\n",
    "    \n",
    "    # this is required as `model.predict` needs a fixed size!\n",
    "    x1_padded = tf.pad(x1, [[0, 0], [0, MAX_LEN - max_len]], constant_values=0.)\n",
    "    x2_padded = tf.pad(x2, [[0, 0], [0, MAX_LEN - max_len]], constant_values=0.)\n",
    "    \n",
    "    padded_model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1_padded,x2_padded])\n",
    "    return model, padded_model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_192():\n",
    "    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    tok = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    padding = tf.cast(tf.equal(ids, PAD_ID), tf.int32)\n",
    "\n",
    "    lens = MAX_LEN - tf.reduce_sum(padding, -1)\n",
    "    max_len = tf.reduce_max(lens)\n",
    "    ids_ = ids[:, :max_len]\n",
    "    att_ = att[:, :max_len]\n",
    "    tok_ = tok[:, :max_len]\n",
    "\n",
    "    config = RobertaConfig.from_pretrained(PATH+'config-roberta-base.json')\n",
    "    bert_model = TFRobertaModel.from_pretrained(PATH+'pretrained-roberta-base.h5',config=config)\n",
    "    x = bert_model(ids_,attention_mask=att_,token_type_ids=tok_)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dropout(Dropout_new)(x[0])\n",
    "    x1 = tf.keras.layers.Conv1D(768, 2,padding='same')(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Conv1D(192, 2,padding='same')(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dropout(Dropout_new)(x1)\n",
    "    x1 = tf.keras.layers.Conv1D(64, 2,padding='same')(x1)\n",
    "    x1 = tf.keras.layers.Dense(1)(x1)\n",
    "    x1 = tf.keras.layers.Flatten()(x1)\n",
    "    x1 = tf.keras.layers.Activation('softmax')(x1)\n",
    "    \n",
    "    x2 = tf.keras.layers.Dropout(Dropout_new)(x[0]) \n",
    "    x2 = tf.keras.layers.Conv1D(768, 2,padding='same')(x2)\n",
    "    x2 = tf.keras.layers.LeakyReLU()(x2)\n",
    "    x2 = tf.keras.layers.Conv1D(192, 2,padding='same')(x2)\n",
    "    x2 = tf.keras.layers.LeakyReLU()(x2)\n",
    "    x2 = tf.keras.layers.Dropout(Dropout_new)(x2) \n",
    "    x2 = tf.keras.layers.Conv1D(64, 2, padding='same')(x2)\n",
    "    x2 = tf.keras.layers.Dense(1)(x2)\n",
    "    x2 = tf.keras.layers.Flatten()(x2)\n",
    "    x2 = tf.keras.layers.Activation('softmax')(x2)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1,x2])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr) \n",
    "    model.compile(loss=loss_fn, optimizer=optimizer)\n",
    "    \n",
    "    # this is required as `model.predict` needs a fixed size!\n",
    "    x1_padded = tf.pad(x1, [[0, 0], [0, MAX_LEN - max_len]], constant_values=0.)\n",
    "    x2_padded = tf.pad(x2, [[0, 0], [0, MAX_LEN - max_len]], constant_values=0.)\n",
    "    \n",
    "    padded_model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1_padded,x2_padded])\n",
    "    return model, padded_model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_lstm():\n",
    "    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    tok = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n",
    "    padding = tf.cast(tf.equal(ids, PAD_ID), tf.int32)\n",
    "\n",
    "    lens = MAX_LEN - tf.reduce_sum(padding, -1)\n",
    "    max_len = tf.reduce_max(lens)\n",
    "    ids_ = ids[:, :max_len]\n",
    "    att_ = att[:, :max_len]\n",
    "    tok_ = tok[:, :max_len]\n",
    "\n",
    "    config = RobertaConfig.from_pretrained(PATH+'config-roberta-base.json')\n",
    "    bert_model = TFRobertaModel.from_pretrained(PATH+'pretrained-roberta-base.h5',config=config)\n",
    "    x = bert_model(ids_,attention_mask=att_,token_type_ids=tok_)\n",
    "    \n",
    "    x1 = tf.keras.layers.Dropout(Dropout_new)(x[0])\n",
    "    x1 = Bidirectional(CuDNNLSTM(784, return_sequences=True, name='lstm_layer',))(x1)\n",
    "    x1 = tf.keras.layers.LeakyReLU()(x1)\n",
    "    x1 = tf.keras.layers.Dense(1)(x1)\n",
    "    x1 = tf.keras.layers.Flatten()(x1)\n",
    "    x1 = tf.keras.layers.Activation('softmax')(x1)\n",
    "    \n",
    "    x2 = tf.keras.layers.Dropout(Dropout_new)(x[0])\n",
    "    x2 = Bidirectional(CuDNNLSTM(784, return_sequences=True, name='lstm_layer',))(x2)\n",
    "    x2 = tf.keras.layers.LeakyReLU()(x2)\n",
    "    x2 = tf.keras.layers.Dense(1)(x2)\n",
    "    x2 = tf.keras.layers.Flatten()(x2)\n",
    "    x2 = tf.keras.layers.Activation('softmax')(x2)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1,x2])\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr) \n",
    "    model.compile(loss=loss_fn, optimizer=optimizer)\n",
    "    \n",
    "    # this is required as `model.predict` needs a fixed size!\n",
    "    x1_padded = tf.pad(x1, [[0, 0], [0, MAX_LEN - max_len]], constant_values=0.)\n",
    "    x2_padded = tf.pad(x2, [[0, 0], [0, MAX_LEN - max_len]], constant_values=0.)\n",
    "    \n",
    "    padded_model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1_padded,x2_padded])\n",
    "    return model, padded_model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def jaccard(str1, str2): \n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    if (len(a)==0) & (len(b)==0): return 0.5\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "ct = train.shape[0]\n",
    "input_ids = np.ones((ct,MAX_LEN),dtype='int32')\n",
    "attention_mask = np.zeros((ct,MAX_LEN),dtype='int32')\n",
    "token_type_ids = np.zeros((ct,MAX_LEN),dtype='int32')\n",
    "start_tokens = np.zeros((ct,MAX_LEN),dtype='int32')\n",
    "end_tokens = np.zeros((ct,MAX_LEN),dtype='int32')\n",
    "\n",
    "for k in range(train.shape[0]):\n",
    "    \n",
    "    # FIND OVERLAP\n",
    "    text1 = \" \"+\" \".join(train.loc[k,'text'].split())\n",
    "    text2 = \" \".join(train.loc[k,'selected_text'].split())\n",
    "    idx = text1.find(text2)\n",
    "    chars = np.zeros((len(text1)))\n",
    "    chars[idx:idx+len(text2)]=1\n",
    "    if text1[idx-1]==' ': chars[idx-1] = 1 \n",
    "    enc = tokenizer.encode(text1) \n",
    "        \n",
    "    # ID_OFFSETS\n",
    "    offsets = []; idx=0\n",
    "    for t in enc.ids:\n",
    "        w = tokenizer.decode([t])\n",
    "        offsets.append((idx,idx+len(w)))\n",
    "        idx += len(w)\n",
    "    \n",
    "    # START END TOKENS\n",
    "    toks = []\n",
    "    for i,(a,b) in enumerate(offsets):\n",
    "        sm = np.sum(chars[a:b])\n",
    "        if sm>0: toks.append(i) \n",
    "        \n",
    "    s_tok = sentiment_id[train.loc[k,'sentiment']]\n",
    "    input_ids[k,:len(enc.ids)+3] = [0, s_tok] + enc.ids + [2]\n",
    "    attention_mask[k,:len(enc.ids)+3] = 1\n",
    "    if len(toks)>0:\n",
    "        start_tokens[k,toks[0]+2] = 1\n",
    "        end_tokens[k,toks[-1]+2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### FOLD 1\n",
      "#########################\n",
      "Loading model...\n",
      "Predicting Test...\n",
      "3534/3534 [==============================] - 15s 4ms/sample\n",
      "#########################\n",
      "### FOLD 2\n",
      "#########################\n",
      "Loading model...\n",
      "Predicting Test...\n",
      "3534/3534 [==============================] - 11s 3ms/sample\n",
      "#########################\n",
      "### FOLD 3\n",
      "#########################\n",
      "Loading model...\n",
      "Predicting Test...\n",
      "3534/3534 [==============================] - 11s 3ms/sample\n",
      "#########################\n",
      "### FOLD 4\n",
      "#########################\n",
      "Loading model...\n",
      "Predicting Test...\n",
      "3534/3534 [==============================] - 11s 3ms/sample\n",
      "#########################\n",
      "### FOLD 5\n",
      "#########################\n",
      "Loading model...\n",
      "Predicting Test...\n",
      "3534/3534 [==============================] - 12s 3ms/sample\n",
      "CPU times: user 1min 16s, sys: 11.3 s, total: 1min 27s\n",
      "Wall time: 1min 41s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "785"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "jac = []; VER='v0'; DISPLAY=1 # USE display=1 FOR INTERACTIVE\n",
    "preds_start1 = np.zeros((input_ids_t.shape[0],MAX_LEN))\n",
    "preds_end1 = np.zeros((input_ids_t.shape[0],MAX_LEN))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_split,shuffle=True,random_state=SEED)\n",
    "for fold,(idxT,idxV) in enumerate(skf.split(input_ids,train.sentiment.values)):\n",
    "\n",
    "    print('#'*25)\n",
    "    print('### FOLD %i'%(fold+1))\n",
    "    print('#'*25)\n",
    "    \n",
    "    K.clear_session()\n",
    "    #gc.collect()#このガベージコレクトには意味があるのか?\n",
    "    \n",
    "    model, padded_model = build_model_base()\n",
    "   \n",
    "    weight_fn = '../input/0716-lucky-model/%s-roberta-%i.h5'%(VER,fold)\n",
    "    \n",
    "    print('Loading model...')\n",
    "    load_weights(model, weight_fn)\n",
    "\n",
    "    print('Predicting Test...')\n",
    "    preds = padded_model.predict([input_ids_t,attention_mask_t,token_type_ids_t],verbose=DISPLAY)\n",
    "    preds_start1 += preds[0]/skf.n_splits\n",
    "    preds_end1 += preds[1]/skf.n_splits\n",
    "#以下を付け加える必要があるかを考察。    \n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# jac = []; VER='v0'; DISPLAY=1 # USE display=1 FOR INTERACTIVE\n",
    "# preds_start2 = np.zeros((input_ids_t.shape[0],MAX_LEN))\n",
    "# preds_end2 = np.zeros((input_ids_t.shape[0],MAX_LEN))\n",
    "\n",
    "# skf = StratifiedKFold(n_splits=n_split,shuffle=True,random_state=SEED)\n",
    "# for fold,(idxT,idxV) in enumerate(skf.split(input_ids,train.sentiment.values)):\n",
    "\n",
    "#     print('#'*25)\n",
    "#     print('### FOLD %i'%(fold+1))\n",
    "#     print('#'*25)\n",
    "    \n",
    "#     K.clear_session()\n",
    "#     #gc.collect()\n",
    "    \n",
    "#     model, padded_model = build_model_drop_bef64()\n",
    "    \n",
    "#     weight_fn = '../input/drop-bef64/add_drop_out_%s-roberta-%i.h5'%(VER,fold)\n",
    "    \n",
    "#     print('Loading model...')\n",
    "#     load_weights(model, weight_fn)\n",
    "\n",
    "#     print('Predicting Test...')\n",
    "#     preds = padded_model.predict([input_ids_t,attention_mask_t,token_type_ids_t],verbose=DISPLAY)\n",
    "#     preds_start2 += preds[0]/skf.n_splits\n",
    "#     preds_end2 += preds[1]/skf.n_splits\n",
    "    \n",
    "# #以下を付け加える必要があるかを考察。    \n",
    "# K.clear_session()\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### FOLD 1\n",
      "#########################\n",
      "Loading model...\n",
      "Predicting Test...\n",
      "3534/3534 [==============================] - 11s 3ms/sample\n",
      "#########################\n",
      "### FOLD 2\n",
      "#########################\n",
      "Loading model...\n",
      "Predicting Test...\n",
      "3534/3534 [==============================] - 11s 3ms/sample\n",
      "#########################\n",
      "### FOLD 3\n",
      "#########################\n",
      "Loading model...\n",
      "Predicting Test...\n",
      "3534/3534 [==============================] - 12s 3ms/sample\n",
      "#########################\n",
      "### FOLD 4\n",
      "#########################\n",
      "Loading model...\n",
      "Predicting Test...\n",
      "3534/3534 [==============================] - 11s 3ms/sample\n",
      "#########################\n",
      "### FOLD 5\n",
      "#########################\n",
      "Loading model...\n",
      "Predicting Test...\n",
      "3534/3534 [==============================] - 11s 3ms/sample\n",
      "CPU times: user 1min 10s, sys: 8.44 s, total: 1min 19s\n",
      "Wall time: 1min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "68462"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "jac = []; VER='v0'; DISPLAY=1 # USE display=1 FOR INTERACTIVE\n",
    "preds_start3 = np.zeros((input_ids_t.shape[0],MAX_LEN))\n",
    "preds_end3 = np.zeros((input_ids_t.shape[0],MAX_LEN))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_split,shuffle=True,random_state=SEED)\n",
    "for fold,(idxT,idxV) in enumerate(skf.split(input_ids,train.sentiment.values)):\n",
    "\n",
    "    print('#'*25)\n",
    "    print('### FOLD %i'%(fold+1))\n",
    "    print('#'*25)\n",
    "    \n",
    "    K.clear_session()\n",
    "    #gc.collect()\n",
    "    \n",
    "    model, padded_model = build_model_192()\n",
    "    \n",
    "    weight_fn = '../input/768-192-64-conv-stable/%s-roberta-%i.h5'%(VER,fold)\n",
    "    \n",
    "    print('Loading model...')\n",
    "    load_weights(model, weight_fn)\n",
    "\n",
    "    print('Predicting Test...')\n",
    "    preds = padded_model.predict([input_ids_t,attention_mask_t,token_type_ids_t],verbose=DISPLAY)\n",
    "    preds_start3 += preds[0]/skf.n_splits\n",
    "    preds_end3 += preds[1]/skf.n_splits\n",
    "\n",
    "#以下を付け加える必要があるかを考察。    \n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### FOLD 1\n",
      "#########################\n",
      "Loading model...\n",
      "Predicting Test...\n",
      "3534/3534 [==============================] - 95s 27ms/sample\n",
      "#########################\n",
      "### FOLD 2\n",
      "#########################\n",
      "Loading model...\n",
      "Predicting Test...\n",
      "3534/3534 [==============================] - 30s 8ms/sample\n",
      "#########################\n",
      "### FOLD 3\n",
      "#########################\n",
      "Loading model...\n",
      "Predicting Test...\n",
      "3534/3534 [==============================] - 29s 8ms/sample\n",
      "#########################\n",
      "### FOLD 4\n",
      "#########################\n",
      "Loading model...\n",
      "Predicting Test...\n",
      "3534/3534 [==============================] - 29s 8ms/sample\n",
      "#########################\n",
      "### FOLD 5\n",
      "#########################\n",
      "Loading model...\n",
      "Predicting Test...\n",
      "3534/3534 [==============================] - 29s 8ms/sample\n",
      "CPU times: user 3min 43s, sys: 9.44 s, total: 3min 53s\n",
      "Wall time: 4min 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72722"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "jac = []; VER='v0'; DISPLAY=1 # USE display=1 FOR INTERACTIVE\n",
    "preds_start5 = np.zeros((input_ids_t.shape[0],MAX_LEN))\n",
    "preds_end5 = np.zeros((input_ids_t.shape[0],MAX_LEN))\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_split,shuffle=True,random_state=SEED)\n",
    "for fold,(idxT,idxV) in enumerate(skf.split(input_ids,train.sentiment.values)):\n",
    "\n",
    "    print('#'*25)\n",
    "    print('### FOLD %i'%(fold+1))\n",
    "    print('#'*25)\n",
    "    \n",
    "    K.clear_session()\n",
    "    #gc.collect()\n",
    "    \n",
    "    model, padded_model = build_model_lstm()\n",
    "    \n",
    "    weight_fn = '../input/lstm768/%s-roberta-%i.h5'%(VER,fold)\n",
    "    \n",
    "    print('Loading model...')\n",
    "    load_weights(model, weight_fn)\n",
    "\n",
    "    print('Predicting Test...')\n",
    "    preds = padded_model.predict([input_ids_t,attention_mask_t,token_type_ids_t],verbose=DISPLAY)\n",
    "    preds_start5 += preds[0]/skf.n_splits\n",
    "    preds_end5 += preds[1]/skf.n_splits\n",
    "\n",
    "#以下を付け加える必要があるかを考察。    \n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## 4. Submission <a class=\"anchor\" id=\"4\"></a>\n",
    "\n",
    "[Back to Table of Contents](#0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Code from notebook https://www.kaggle.com/khoongweihao/tse2020-roberta-cnn-random-seed-distribution?scriptVersionId=34448972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "preds_start = preds_start1*0.83 + preds_start3*0.1 + preds_start5*0.07\n",
    "preds_end =  preds_end1*0.83 + preds_end3*0.1 + preds_end5*0.07\n",
    "\n",
    "# preds_start = preds_start1\n",
    "# preds_end = preds_end1\n",
    "\n",
    "all = []\n",
    "for k in range(input_ids_t.shape[0]):\n",
    "    a = np.argmax(preds_start[k,])\n",
    "    b = np.argmax(preds_end[k,])\n",
    "    if a>b: \n",
    "        st = test.loc[k,'text']\n",
    "    else:\n",
    "        text1 = \" \"+\" \".join(test.loc[k,'text'].split())\n",
    "        enc = tokenizer.encode(text1)\n",
    "        st = tokenizer.decode(enc.ids[a-2:b-1])\n",
    "    all.append(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " test_raw = pd.read_csv('../input/tweet-sentiment-extraction/test.csv').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3534, 3) (3534, 3)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape, test_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['selected_text'] = all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def rm_url(text): \n",
    "    text = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "    return ''.join(text)\n",
    "\n",
    "def rm_underbar(text):\n",
    "    text = re.sub('^_.{2,}?\\s', '', text)\n",
    "    return ''.join(text)\n",
    "\n",
    "def post_process(s):\n",
    "    a = re.findall('[^A-Za-z0-9]',s)\n",
    "    b = re.sub('[^A-Za-z0-9]+', '', s)\n",
    "\n",
    "    try:\n",
    "        if a.count('.')==3:\n",
    "            text = b + '. ' + b + '..'\n",
    "        elif a.count('.')==4:\n",
    "            text = b + '. ' + b + '..' + b + '...'\n",
    "        elif a.count('!')==4:\n",
    "            text = b + '! ' + b + '!! ' +  b + '!!!'\n",
    "        else:\n",
    "            text = s\n",
    "        return text\n",
    "    except:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_raw = pd.read_csv('../input/tweet-sentiment-extraction/test.csv').fillna('')\n",
    "# for k in range(test.shape[0]):\n",
    "#     if test.loc[k, 'sentiment'] == 'positive' or 'negative':\n",
    "#         if len(test.loc[k, 'text'].split()) <= 3:\n",
    "#             test.loc[k, 'selected_text'] = rm_url(test_raw.loc[k, 'text'])\n",
    "# #     if test.loc[k, 'sentiment'] == 'neutral': \n",
    "# #         test.loc[k, 'selected_text'] = rm_url(test_raw.loc[k, 'text'])\n",
    "\n",
    "# test['selected_text'] = test['selected_text'].apply(lambda x: x.replace('!!!!', '!') if len(x.split())==1 else x)\n",
    "# test['selected_text'] = test['selected_text'].apply(lambda x: x.replace('..', '.') if len(x.split())==1 else x)\n",
    "# test['selected_text'] = test['selected_text'].apply(lambda x: x.replace('...', '.') if len(x.split())==1 else x)\n",
    "# test['selected_text'] = test.apply(lambda x: post_process(x['selected_text']) if (len(str(x['selected_text']).split())==1) else x['selected_text'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3444</th>\n",
       "      <td>7d32d4866a</td>\n",
       "      <td>You are sooo lucky. My fiance is aw...</td>\n",
       "      <td>positive</td>\n",
       "      <td>lucky.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>200f2b3566</td>\n",
       "      <td>you shouldnt have to reset more tha...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>you shouldnt have to reset more tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3136</th>\n",
       "      <td>43c61eb7a3</td>\n",
       "      <td>I can`t find my camera</td>\n",
       "      <td>negative</td>\n",
       "      <td>i can`t find my camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>334954f215</td>\n",
       "      <td>hey peoples, dont you just hate bein...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>hey peoples, dont you just hate bei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208</th>\n",
       "      <td>2dfbe0b7fb</td>\n",
       "      <td>Hmmm. http://www.djhero.com/ is down</td>\n",
       "      <td>negative</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>8986091fd3</td>\n",
       "      <td>wishes happy mothers` day to all mom...</td>\n",
       "      <td>positive</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>7dd51bdec1</td>\n",
       "      <td>reading Evermore by Lynn Viehl.</td>\n",
       "      <td>neutral</td>\n",
       "      <td>reading evermore by lynn viehl.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>5ff525b74b</td>\n",
       "      <td>Wondering if i cld make things any w...</td>\n",
       "      <td>negative</td>\n",
       "      <td>worse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>f9382a1f7b</td>\n",
       "      <td>oooh, sunshine! A patch of sunshine!...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>oooh, sunshine! a patch of sunshine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>7720aca199</td>\n",
       "      <td>No, that`s not right - I remember n...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>no, that`s not right - i remember n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          textID                                     text sentiment  \\\n",
       "3444  7d32d4866a   You are sooo lucky. My fiance is aw...  positive   \n",
       "749   200f2b3566   you shouldnt have to reset more tha...   neutral   \n",
       "3136  43c61eb7a3                   I can`t find my camera  negative   \n",
       "26    334954f215  hey peoples, dont you just hate bein...   neutral   \n",
       "3208  2dfbe0b7fb     Hmmm. http://www.djhero.com/ is down  negative   \n",
       "2095  8986091fd3  wishes happy mothers` day to all mom...  positive   \n",
       "843   7dd51bdec1          reading Evermore by Lynn Viehl.   neutral   \n",
       "172   5ff525b74b  Wondering if i cld make things any w...  negative   \n",
       "100   f9382a1f7b  oooh, sunshine! A patch of sunshine!...   neutral   \n",
       "930   7720aca199   No, that`s not right - I remember n...   neutral   \n",
       "\n",
       "                                selected_text  \n",
       "3444                                   lucky.  \n",
       "749    you shouldnt have to reset more tha...  \n",
       "3136                   i can`t find my camera  \n",
       "26     hey peoples, dont you just hate bei...  \n",
       "3208                                     down  \n",
       "2095                                    happy  \n",
       "843           reading evermore by lynn viehl.  \n",
       "172                                     worse  \n",
       "100    oooh, sunshine! a patch of sunshine...  \n",
       "930    no, that`s not right - i remember n...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[['textID','selected_text']].to_csv('submission.csv',index=False)\n",
    "test.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "There are a number of clear clusters that allow us to hope that we can improve the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "[Go to Top](#0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
